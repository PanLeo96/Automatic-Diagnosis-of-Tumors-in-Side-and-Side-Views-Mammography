function [y1] = nn_R(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 19-Jul-2020 18:08:08.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = Qx2 matrix, input #1
% and returns:
%   y = Qx1 matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0;0];
x1_step1.gain = [2;2];
x1_step1.ymin = -1;

% Layer 1
b1 = [6.2610235268347746995;5.5663288339464083165;-4.9428409403340936024;4.2893463444277006857;3.6183796753394528167;2.9657290124154314093;2.3066467978823776974;1.6477943120040676739;-1.0148268750137301453;0.32952482962181633974;0.32952533159779123784;0.98422176320730558885;-1.64767750851427075;2.4043122491426314191;-2.9639749719947001694;-3.6154820713823312417;4.2852540720288603282;4.9552600950268894664;-5.6018455453558848589;-6.2611994770235641639];
IW1_1 = [-4.1830137357150922739 4.6585167333959960345;-1.1132443135570844195 -6.1981993300855711126;4.6164152466414343223 -4.2295047676670156633;-6.0291675991525766065 1.6736411399719339776;-2.7501807117997061347 -5.6279253768202286423;-4.6805003696573885819 -4.1584753777484593229;-6.0183491612333286369 -1.7261905080254642542;-6.2356759078628032356 0.5607778372259197841;3.7615348192347628498 -4.9993412979867617452;-6.0507358036357734576 -1.6089025087210349074;0.36474944146762816599 6.2503563624853910596;5.6134834729409055498 -2.7766495992004127658;-6.2314971853160345816 0.60654556254325753262;2.9363825985278335651 -5.4828312318605680886;-2.3780138249854205768 -5.7928397980264954015;-1.7965764222002305051 6.0042014686391818046;1.3751886470114857985 6.107106834269893092;6.2315916674933333752 0.46325755066993040687;-4.3365366126182358641 4.516177072340506804;-4.8249808436292180858 3.9894754721613745474];

% Layer 2
b2 = 0.23033363972966855449;
LW2_1 = [-0.490380185023396864 -1.0917715606644282644 0.35134548225192374638 0.085709042488456385622 -0.64453270064826473362 0.31365859432779480409 0.21224409602598653946 0.65052297722257335089 -0.47069794787512547751 -0.43267255205740429158 -0.28611347063496572751 -0.88675146746700761469 -0.53539928207879361466 0.67289784974078858948 -0.83095339984997096394 0.15382760385442001416 -0.75649107445006946726 0.79730791237849352182 0.73493138913757682928 -0.59853326281118568453];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,1); % samples

% Input 1
x1 = x1';
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
y1 = y1';
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
