function [y1] = final_NN()
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 19-Jul-2020 18:53:24.
%
% [y1] = myNeuralNetworkFunction() takes these arguments:
% and returns:
%   y = Qx1 matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Layer 1
b1 = [0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0];

% Layer 2
b2 = 0;
LW2_1 = [0.51195824186563088087 -0.95494565723802304902 -0.45236862734041333178 0.69865709089092997708 -0.85693348032997074259 -0.44683706787383203896 0.64201411084324466749 -0.48300762074555902981 0.33134958238541339925 0.54662865060079135482 0.5074299713627560271 0.39766781074904472559 -0.37484369848081772192 0.59629054776404688543 0.67146544173684763468 0.42695039460450984192 -0.75907018508905721443 -0.4698881607547106265 -0.44836264059821773209 1.2009525956562658866];

% ===== SIMULATION ========

% Dimensions
Q = 0; % samples

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q));

% Layer 2
a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
y1 = y1';
end

% ===== MODULE FUNCTIONS ========

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
