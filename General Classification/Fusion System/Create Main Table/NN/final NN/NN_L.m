function [y1] = nn_L(x1)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 19-Jul-2020 18:02:58.
%
% [y1] = myNeuralNetworkFunction(x1) takes these arguments:
%   x = Qx2 matrix, input #1
% and returns:
%   y = Qx1 matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0;0];
x1_step1.gain = [2;2];
x1_step1.ymin = -1;

% Layer 1
b1 = [6.2608571964470582927;-5.6020471267749076816;-4.9405212959874988954;4.2892440256289203759;-3.6251837913427515936;3.020047496734164838;-2.3066413447998241892;-1.6476280440102042402;0.98628867791296237488;-0.32952527942523629489;-0.32952304344051847051;-0.98829345162511450518;1.641329783331643366;2.3148751108913336871;-3.0525609120385803763;3.6255476460107063374;4.2836168569981545318;4.9425399721591523061;-5.6035255237261454297;6.3342252056943282312];
IW1_1 = [-3.1045625810999180061 5.4371235309340670838;0.51706778021815202884 6.2394906427187670772;1.2511834664436873865 6.1367486402727449146;-1.5362135134999597152 6.0655581214409863833;1.2951933054882369678 6.1252362149934933555;-2.2522190535711850146 5.8082112274483552739;6.2583503205216706178 0.18318839820018170683;6.0244496911756959534 1.7047045845970527633;-5.2066179219527279898 3.4786431144806262417;5.8829008944910583523 -2.1426503005619146336;-5.9021372459286540746 -2.0892096192985589731;-3.882993651756456277 -4.9113923314916902996;5.1572106238639108255 3.5529289046147130016;5.6596529042344014826 -2.6681761139921786885;-5.4235129138356317213 3.0593899086610334415;3.7245625186975441778 -5.032449231163193204;4.7825176345086610752 -4.0407721684288961939;2.9819232649847338124 5.5058174974417095626;-1.586927119964475219 6.0553453817485465294;0.56571115708902319774 6.1550673057425999701];

% Layer 2
b2 = -0.095811990312143727189;
LW2_1 = [0.5315777042660192464 0.16122612650529746792 0.55061289411798552962 0.033835923632353888391 -0.065399257183169939855 -0.49826223511131306765 1.2273048750744792734 1.2837298898803073399 -0.2698829940170319186 -0.053471757504132660932 -0.026358425398028156872 0.62078569819103912586 -1.0408050127791950157 0.019913079661634885964 0.78003676918364772686 0.45524939745108428113 0.37940241277546382648 0.93712301551780952114 -0.011689873176719309256 -0.63909275992691927382];

% ===== SIMULATION ========

% Dimensions
Q = size(x1,1); % samples

% Input 1
x1 = x1';
xp1 = mapminmax_apply(x1,x1_step1);

% Layer 1
a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);

% Layer 2
a2 = logsig_apply(repmat(b2,1,Q) + LW2_1*a1);

% Output 1
y1 = a2;
y1 = y1';
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Sigmoid Positive Transfer Function
function a = logsig_apply(n,~)
a = 1 ./ (1 + exp(-n));
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
